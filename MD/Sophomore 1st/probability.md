# 概率论
非确定现象包含随机现象，是由于微小变化因素的综合影响导致的
## 随机事件和随机变量
### 随机试验
1. 可以重现
2. 知道结果集合
3. 不知道具体结果
### 随机事件
即每一个结果。它可能发生也可能不发生
#### 复合事件
由不可被分解的基本事件组合而成
#### 样本空间
基本事件全体集合。其中每个基本事件叫做一个样本点
### 随机事件关系
#### 包含
A发生B必然发生，则事件B包含事件A
#### 和事件（并集）
A和B至少发生一个则和事件发生
#### 积事件（交集）
A和B同时发生则积事件发生
#### 互不相容/互斥事件
A、B不同时发生

样本空间的基本事件互为互斥事件
#### 对立事件/逆事件
A和B在一次实验中非此即彼（不同时发生、且不发生其他事件）
#### 差事件
A-B

A发生但B不发生
#### 完备事件组/有限划分
多个事件互斥、加和为全集。
## 概率
可能性大小的客观度量
### 频率
实验量，一定程度上反映了概率

具有稳定性
### 古典概率
有限多个基本事件，且每个基本事件的可能性相等
### 公理化概率
1. 非负性：事件概率在01之间
2. 规范性：总概率为1
3. 可列可加性：互斥的事件概率之和==事件和之概率
### 运算律
#### 加法公式
$$
P(A∪B) = P(A) + P(B) - P(AB)
$$
*减去相交部分*
#### 减法公式（包含关系下）
$$
P(A-B) = P(A) - P(AB)
$$
*只减去A中的B部分*
#### 对立事件
$$
P(A^-) = 1 - P(A)
$$
*非A即B*
#### 分配律
$$
P\{(A∪B)C\} = P\{(AC)∪(BC)\}
$$
$$
P\{(AB)∪C\} = P\{(A∪C)∩(B∪C)\}
$$
*交并可互相分配*
#### 对偶律
*长杠变短杠，开口变方向*
#### 条件概率（变换得到乘法公式）
- A发生的条件下B发生：
$$
P(B|A) = {P(AB) \over P(A)}
$$
*A发生的条件下B不发生为其对立事件*
#### 抽签原理
*抽取顺序与概率无关（即使是不放回）*
### 全概率公式（事前推断）
- 当概率P可被拆分为多种情况，则其概率之和为P
$$
P(A) = \sum^n_{i = 1}P(AB_i) = \sum^n_{i = 1}P(A|B_i)P(B_i)
$$
### 贝叶斯公式（事后概率）
- 已知A发生，需要判断其具体从属<br>分母是总体，分子是部分
$$
P(B_i|A) = {P(B_iA) \over P(A)} = {P(A|B_i)P(B_i) \over \sum_{j = 1}^nP(A|B_j)P(B_j)}
$$
### 事件的独立性：P(AB)=P(A)P(B)
- A事件发生的概率不受B的影响，即
$$
P(A|B)=P(A|B^-)=P(A)
$$
- 独立具有对称性，即A，B相互独立（A与B逆，B与A逆，A逆与B逆也独立）

有定理：

    P(AB)=P(A)P(B)等价于A,B独立

- 空集$\phi$和全集$\omega$与任何事件都独立
- 概率为0和1的事件均独立
- 独立不可能互不相容
$$
P(A|B)+P(A^-|B)=1
$$
$$
P(A|B^-)+P(A^-|B^-)=1
$$
即B发生与否与A无关

在讨论三者相互独立时，不仅要讨论两两独立，还要讨论三者独立

#### 古典概率解题法
1. 写出样本空间
2. 互不相容判断事件交集是否空集
3. 独立判断概率相乘
#### 全概率解题法
1. 假设事件A、说明有限划分B
2. 计算B和条件概率B|A
3. 代入全概率公式
4. 计算结果
## 随机变量分布
### 随机变量
取值由试验结果确定、有统计规律性
### 分布律（分布函数）
函数值代表随机点落在负无穷到某值的概率
- 单调不减（作为拆函数依据）
- 0，1之间
- 右侧连续（小于等于）

判离散、连续

    只有可列个数值是离散型，连续可以取区间任意值概率存在
    连续型必须处处连续
### 离散型随机变量
X的所有取值$x_k$（可为可列无限个）

分布律形式
$$
P\{X=x_k\}=P_k
$$
非负性
$$
P_k>=0
$$
合为一
$$
\sum P_k>=1
$$
### 连续型随机变量
F(x)为随机变量X的分布函数<br>则有f(x)为F(x)的概率密度
$$
F(x)=\int ^x _{-\infty} f(x)dt
$$
(1)F(x)连续

(2)对于任意实数x$\in$R有
$$
P\{X=x_0\}=0
$$
即单点概率为0，但并非意味着不可能事件
概率为1的事件也未必是必然事件

####  概率密度函数f(x)的性质：积分即是概率函数（反映取到x附近值的大小）
(1)f(x)>=0;

(2)$\int _{-\infty} ^{+\infty} f(t)dt=1$

(3)$P\{x_1<X<=x_2\}=P\{x_1<=X<x_2\}$

=$\int _{x_1} ^{x_2}f(x)dt$

概率无所谓开闭区间（即取某个点的概率为0）

(4)f(x)在x处连续，则有F'(x)=f(x)
### 离散型随机变量分布
#### 0-1分布（不是1就是0）
二项分布,n=1特例
#### 几何分布（某事首次发生发生）：X~G(p)
$$
P\{X=k\}=(1-p)^{k-1}p
$$
#### 二项分布（n次里发生了k次）:X~B(n,p)
$$
P\{X=k\}=p^k(1-p)^{1-k}，k=0,1,2,3...n
$$
#### 泊松分布（近似n大(>=100)而p小，np适中(<=10)的二项分布）:X~P(λ)
$$
P\{X=k\}={{\lambda^k}\over{k!}}e^{-\lambda},k=0,1,2,3...,\lambda>0
$$
查表而不计算<br>在近似二项分布时，用np代入$\lambda$
#### 几何分布
$$
P\{X=m\}=(1-p)^{m-1}p
$$
#### 超几何分布（分成两类。当N很大n很小，不放回抽样可以近似看作放回抽样，用二项分布近似）
$$
P\{X=k\}={C^k_{N_1}C^{n-k}_{N_2}\over C^n_N},k=0,1,2,3...
$$
### 连续性随机变量分布
#### 均匀分布
概率是长度的倒数，区间开闭与概率无关
$$
f(x)= \{^{{1 \over {b-a}} ,a<x<b;}_{0,其他}
$$
大量实验服从均匀分布<br>分布函数：
$$
F(x)={x-a\over b-a},a<=x<b,小于a为0，大于等于b为1
$$
#### 指数分布(某些消耗性产品的寿命)：X~Exp($\lambda$)
$$
f(x)=\{^{\lambda e^{-\lambda x},x>0(\lambda>0)} _{0,其他}
$$
$$
F(x)=\{^{0,x<0} _{1-e^{-\lambda x},x>=0}
$$
指数分布无后效性(无论何时概率都一样)
$$
P\{X>t+s|X>t\}=P\{X>s\}
$$
#### <font color=6662aa>正态分布X~N($\mu,\sigma^2$)</font>
$$
\phi (x;\mu,\sigma ^2)={1 \over {\sqrt {2\pi}\sigma}}e^{-{{(x-\mu)^2} \over {2\sigma^2}}}
$$
图像关于x=$\mu$对称（最大值），决定图像位置<br>$\sigma$越大，图像越平（数据越分散）<br>$1\sigma$处有拐点

标准正态：X~N(0,1)$(\mu = 0,\sigma = 1)$
$$
\phi_0(x)={1\over \sqrt{2\pi}}e^{-{x^2 \over 2}}
$$
对称轴为y轴（偶函数）
$$
P=\Phi(b)-\Phi(a)
$$

对于非标准正态分布采用标准化（x为数据上界）
$$
\phi (x)={1\over \sigma}\phi _0({x-\mu \over \sigma})
$$
概率分布函数为：
$$
\Phi(x)=\Phi _0({x-\mu \over \sigma})
$$
即
$$
P=\Phi({{x_1 - \mu} \over \sigma})-\Phi({{x_2 - \mu} \over \sigma})
$$
$3\sigma$原则：$+-3\sigma$概率占有0.9974几乎为1

上侧分位数：给定概率值$\alpha$，使大于u的概率正为$\alpha$
$$
P\{X>u_\alpha\}=\alpha
$$
即称u为上侧分位数

双侧分位数：给定概率值$\alpha$，为正负u两端的概率之和
$$
P\{|X|>u_{\alpha \over 2}\}=\alpha
$$
u下标为概率值
## 多维随机变量
### 二维随机变量及其分布
二维随机变量组合来自同一样本空间

    对于每一样本点有两个实数与其对应
    称该有序数组（X,Y）为二维随机变量
#### 联合分布函数
$$
F(x,y)=P\{X<=x,Y<=y\}
$$
即从负无穷到给定值的矩形区域
$$
P\{x_1<X<=x_2，y_1<X<=y_2\}=F(x_2,y_2)-F(x_1,y_2)-F(x_2,y_1)+F(x_1,y_1)
$$
##### 边缘分布函数
$F_X(x)$,即y为正无穷，x的一维分布

$F_Y(y)$,即x为正无穷，y的一维分布

#### 联合分布函数的性质：

    单调不减（对x,y）
    有界性：0<=F(x,y)<=1；至少一个趋近于负无穷F趋近于0，全部趋近于正无穷F趋近于1
    右连续性
    相容性

相容性：$F(x_2,y_2)-F(x_1,y_2)-F(x_2,y_1)+F(x_1,y_1)>=0$
>即一个矩形区间概率不为0

对于n维变量，有确定k个变量的k维边缘分布函数

联合分布不仅和边缘分布有关，还和每个分量之间的联系有关
#### 联合分布律
$$
p_{ij}>=0
$$
累加概率为1<br>总概率：累加左下角离散点

边缘分布律

    一变量不动，另一变量累加

分布律给出：
$$
P\{x=i,y=j\}
$$
边缘分布律无法确定联合分布律（部分不能推整体），这与分量之间的联系有关

#### 二维两点分布
分区域划概率
#### 联合概率密度
$$
F(x,y)=\int ^y _{-\infty}\int ^x _{-\infty}f(x,y)dxdy
$$
f(x,y)非负、积分为1、对F(x,y)混合偏导得到f(x,y)、概率为对该区域进行积分<br>
边缘概率密度：<br>$f_X(x)=\int ^{+\infty} _{-\infty}f(x,y)dy$<br>$f_Y(y)=\int ^{+\infty} _{-\infty}f(x,y)dx$

联合密度积一次是边缘密度，积两次是联合分布
#### 二维均匀分布
概率为面积的倒数，与形状和位置无关
### 随机变量的独立性
随机变量相互独立：相乘概率为概率相乘<br>
随机变量：
$$
P\{X<=x,Y<=y\}=P\{X<=x\}P\{Y<=y\}
$$
即联合分布函数等于边缘分布函数之积
$$
F(x,y)=F_X(x)F_Y(y)
$$
离散型每点独立才独立，连续型可以有几个点、线不成立（因其面积为0），找到一个非0区域不等时才不成立
>在二维正态
$(X,Y)~N(\mu _1,\sigma _1^2,\mu _2,\sigma _2^2,\rho)$中，X，Y相互独立即$\rho$为0

多维独立

$$
F(x_1,\dots,x_n)= \prod _{i=1}^nF_i(x_i)
$$
n维随机变量相互独立，则任意k个变量相互独立

### 条件分布
#### 条件分布律
- 离散型
$$
P\{X=x_i|Y=y_j\}={p_{ij}\over p_{\cdot j}},P\{Y=y_j\}>0,i=1,2,\dots
$$
非负、和为1
#### 条件分布函数$F_{X|Y}(x|y)$
- 连续型
$$
F_{X|Y}(x|y)=\lim _{\Delta y ->0^+}P\{x<=X|y<Y<=y+\Delta y\}=\int ^x _{-\infty}{f(u,y_0)\over f_Y(y_0)}du
$$
Y值确定的情况下，x的条件概率密度为：
$$
f_{X|Y}(x|y_0)={f(x,y_0)\over f_Y(y_0)}
$$
且有
$$
\int ^{+\infty} _{-\infty}f_{X|Y}(x|y)dx=1
$$
随机变量独立：联合=边缘相乘/联合就是边缘
### 随机变量函数及其分布
- 以随机变量为自变量构造的函数仍然是随机变量
- 希望通过已知分布推测未知分布
 
 >确定分布律的取值和概率：取值代入函数，概率视情况合并（满足条件的x取值的集合概率并给y）<br>高维同理，可能有多个向量对应一个取值，则将其合并
 #### 离散卷积公式（头尾相乘再相加）
 $$
 P\{X+Y=m\}=\sum _{k=0} ^m p(k)q(m-k),m=0,1,2\dots
 $$
 p为X的边缘分布函数，q为Y的边缘分布函数<br>独立的边缘分布函数相乘得到联合分布函数<br>因为取值不同时互不相容，有取值求和得到边缘分布函数
 - 将独立的二项分布X~B(n1,p),Y~B(n2,p)代入公式
 - 则X+Y~B(n1+n2,p)
 - 二项分布是可加的
 - 将独立的泊松分布X~P(λ1),Y~P(λ2)代入公式
 - 则X+Y~P(λ1+λ2)
 - 泊松分布是可加的
#### 连续性随机变量函数和密度
求解关键

    从Y的分布函数F(Y)出发
    对于Y<y，用g(X)<y代替，再把x孤立出来（记得符号状态）
    即P{X<?,X>?}
    代表X的概率密度函数在此区间积分
    对于分段函数，根据x的分段点代入y得到y分段点
    当g(X)恒单调时，
$$f_Y(y)=[h(y)]|h^`(y)|$$
相互独立性的正态分布的平方和为卡方分布<br>
当X服从正态分布，则X的线性函数Y=aX+b服从Y~$N(a\mu + b, a^2\sigma ^2)$<br>标准正态转换：$a={1\over \sigma}, b=-{\mu \over \sigma}$
#### 连续型卷积公式
Z=X+Y<br>左为边缘分布z的概率密度，右为二维联合分布概率密度

通过x+y=z替换得到
$$
f_Z(z)=\int f(x,z-x)dx
$$
独立时则可写成
$$
f_Z(z)=\int f_X(x)f_Y(z-x)dx
$$
通过条件给出G范围
$$
f(x,z-x)=?,(x,z)\in G
$$
根据范围进行积分

均匀分布不具备可加性（加和得到辛普森分布）<br>两个相互独立的正态分布相加减则$\mu$直接相加减($\sigma^2$相加而不是$\sigma$，且即使分布相减一定相加)
## 随机变量的数字特征
### 数学期望（均值）
#### 离散型数学期望
按照概率大小的加权平均
$$
E(X)=\sum ^{+\infty} _{i=1}x_ip_i
$$
该级数必须绝对收敛，因此部分随机变量数学期望不存在
#### 连续性数学期望
$$
E(X)=\int ^{+\infty} _{-\infty}xf(x)dx
$$
该积分必须绝对收敛，因此不是所有期望都存在
#### 随机变量函数的期望
离散型
$$
E(X)=\sum ^{+\infty} _{i=1}g(x_i)p_i
$$
连续型
$$
E[g(x)]=\int _{-\infty} ^{+\infty}g(x_i)f_x(x_i)dx
$$
eg.$E[x^2]=\int _{-\infty} ^{+\infty}x^2f_x(x)dx$

二维离散
$$
E(Z=g(x,y))=\sum ^n_{i=0}\sum ^n_{j=0} g(x_i,y_i)p_{ij}
$$
二维连续
$$
E(Z=g(x,y))=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}g(x,y)f(x,y)dxdy
$$
#### 期望性质
常数的期望为常数本身<br>线性性：即线性计算（数乘、常数）可以提到期望外，结果不变<br>和的期望即期望之和<br>且当XY相互独立时，有积的期望即期望之积
$$
E(XY)=E(X)E(Y)
$$
### 方差
衡量数据偏离期望的程度
$$
D(X)=E(X-E(X))^2
$$
#### 离散型方差
$$
D(X)=\sum (X_k-E(X))^2p_k
$$
#### 连续型方差
$$
D(X)=\int (X-E(X))^2f(x)dx
$$
*核心科技*
$$
D(X)=E\{[X-E(X)]^2\}=E(X^2)-[E(X)]^2
$$
#### 方差性质

常数方差为0<br>方差加常数不影响方差<br>数乘后方差乘数乘的平方<br>$D(kX+b)=k^2D(X)$<br>在X、Y相互独立时，其和、差加减之方差均为方差之和<br>不独立是有一个2倍协方差的
#### 典型分布的期望和方差
1. 两点分布 X~B(1,p)：E(X)=p，D(X)=p(1-p)=pq
2. 二项分布 X~B(n,p)：E(X)=np，D(X)=np(1-p)=npq
3. 几何分布 E(X)=1/p，D(X)=$1-p\over p^2$
4. 泊松分布 X~P($\lambda$)：E(X)=$\lambda$，D(X)=$\lambda$
5. 均匀分布 X~U(a,b)：E(X)=${a+b \over 2}$，D(X)=$(b-a)^2/12$
6. 指数分布 X~Exp($\lambda$)：E(X)=${1/\lambda}$，D(X)=$1/\lambda^2$
7. 正态分布 X~N($\mu,\sigma ^2$)：E(X)=$\mu$，D(X)=$\sigma^2$
### 协方差、相关系数、矩
#### 协方差
定义
$$
Cov(X,Y)=E((X-E(X)(Y-E(Y))))
$$
计算
$$
Cov(XY)=E(XY)-E(X)E(Y)
$$
易知独立的协方差为0，但协方差为0不一定独立

在方差性质中，有$D(X+-Y)=D(X)+D(Y)+-2Cov(X,Y)$
#### 相关系数——探讨二维变量相关程度
$$
\rho={Cov(X,Y)\over \sqrt{D(X)D(Y)}}
$$
和协方差同符号

相关系数是有界的
$$
|\rho|<=1或\rho^2<=1
$$
当$|\rho|=1$时，X和Y之间满足线性关系。正为完全正相关、负为完全负相关<br>接近0时则说X和Y的线性关系很弱，等于0时则说X和Y不存在线性关系
#### 相关和独立
相关：在此指线性相关

独立则是互不影响（包括不存在线性关系、也不存在非线性关系）

即是说，独立一定不相关（不存在任何关系）、相关一定不独立（已经有线性关系）；<br>不相关不一定独立（可以有非线性关系），不独立不一定相关（可能是非线性关系）
#### 矩
- 原点矩（以原点为中心的中心矩）：
$$
E(X^k)=离散\sum x_i^kp_i=连续\int x^kf(x)dx
$$
期望即是一阶原点矩

- 中心矩：
$$
E(X-E(X))^k=离散\sum (x_i-E(X)^k)p_i=连续\int (x-E(X))^kf(x)dx
$$
0即是一阶中心矩<br>方差即是二阶中心矩
## 大数定律——大量重复实验平均结果稳定
只有在判定变量和其期望的关系时才能使用大数定律和切比雪夫不等式
### 马尔科夫不等式
$$
P\{|Y|>=\epsilon\}<=E^k(|Y|)/\epsilon^k
$$
### 切比雪夫不等式
随机变量X存在E(X)和D(X)，则任给一正数$\epsilon$，有
$$
P(|X-E(X)|>=\epsilon)<=D(X)/\epsilon^2
$$
即，该变量落在双侧$\epsilon$外的概率上界是一个数<br>这个数和方差有关和由常数$\epsilon$有关（方差越小波动越小，范围越大出界越少，平方可能和量纲有关）

- 收敛

    级数在某项之后向某一个数靠近（落在由$\epsilon$为半径的某个区域里）
- 依概率收敛

    级数在某项之后总体以概率1落在由$\epsilon$为半径的某个区域里（但不排除有个别点不在）
#### 伯努利大数定律
在n重伯努利实验中，有
$$
\lim_{n->+\infty}P\{|{m_n\over n}-p|<\epsilon\}=1
$$
即当n趋近于无穷时，频率$m_n\over n$依概率收敛于概率p<br>直观来看是频率落在以概率为中心的小范围内的概率是1
#### 切比雪夫大数定律
由切比雪夫不等式推得

有一系列随机变量X互不相关，期望和方差都存在，且方差有界（$D(X_i)<=M$），任给正数$\epsilon$，有
$$
\lim _{n->\infty}P\{|1/n\sum^n_{i=1}X_i-E(1/n\sum^n_{i=1}X_i)|<\epsilon\}=1
$$
即变量均值依概率收敛于期望均值
#### 独立同分布大数定律
有一组独立同分布的随机变量X，满足$E(X)=\mu,D(X)=\sigma^2$，任给正数$\epsilon$，有
$$
\lim _{n->\infty}P\{|1/n\sum^n_{i=1}X_i-\mu|<\epsilon\}=1
$$
是对切比雪夫大数定律的简化
#### 辛钦大数定律
有一组独立同分布的随机变量X，满足$E(X)=\mu$，**方差有没有无所谓**<br>独立同分布大数定律仍然成立
## ~~中心~~极限定理——用于概率近似计算

- 研究大量独立同分布随机变量之和的极限分布——几乎都是正态分布

随机变量序列X独立同分布、有有限的期望和方差<br>有标准化随机变量
$$
Y_n={\sum^n_{k=1} X_k-\sum^n _{k=1} E(X_k)\over \sqrt{\sum^n _{k=1} D(X_k)}}={\sum^n_{k=1} X_k-n\mu\over \sqrt{n}\sigma}（正态简化写法）
$$
$\lim_{n->\infty}P\{Y_n<=y\}=\Phi(y)$<br>即称X序列服从中心极限定理

大量独立同分布之和标准化之后为标准正态，当n足够大时可以用正态分布近似（标准化后可以用标准正态分布近似）

即有 $\sum^n _{k=1}X_k$~$N(\sum^n _{k=1} E(X_k),\sum^n _{k=1} D(X_k))$

计算时，有
$$
P\{x_1<Y_n<x_2\}=\Phi(x_2)-\Phi(x_1)
$$
### 独立同分布中心极限定理（林德伯格——列维定理）
若有*相互独立*、*同分布*序列X（期望和方差一致），$E(X_k)=\mu$，$D(X_k)=\sigma ^2$，则X满足中心极限定理
$$
{\sum^n _{k=1} X_k-\sum^n _{k=1} E(X_k)\over \sqrt{\sum^n _{k=1} D(X_k)}}={\sum^n _{k=1} X_k-n\mu\over\sqrt{n}\sigma}
$$
当n很大时，可以看作标准正态分布
$$
\lim _{n->\infty}P\{{\sum^n _{k=1} X_k-n\mu\over\sqrt{n}\sigma}<x\}=\Phi(x)
$$
或
$$
\lim _{n->\infty}P\{x_1<\sum^n _{k=1} X_k<x_2\}=\Phi({{x_2-n\mu}\over \sqrt{n}\sigma})-\Phi({{x_1-n\mu}\over \sqrt{n}\sigma})
$$
### D-L中心极限定理（独立同分布在二项分布下的特殊情形）
有随机变量序列Y~B(n,p),可用
$$
\lim _{n->\infty}P\{{Y_n-np\over\sqrt{np(1-p)}}\}=\Phi(x)
$$
# 统计
参数估计问题、假设检验问题

研究收集和整理随机数据并分析从而做出推断
## 总体、样本和统计量
#### 总体（随机变量）：
研究对象的单元组成的集合<br>个体：每个单位元素<br>整体和局部的关系

#### 样本：
按规则从整体中抽取的个体<br>样本容量：样本中个体数量<br>用一个n维随机向量表示这一组随机变量<br>其值称为样本值

为使样本具有代表性：

    使样本和总体同分布
    且样本之间相互独立
    称为简单随机样本

总体的分布函数为F(x)时，样本的联合分布函数是每个样本值代入分布函数并相乘
#### 统计量
样本的函数，不含任何未知参数

常用统计量：

    样本均值：算术平均
    样本方差：和均值的方差
    样本k阶原点矩：k次方的算术平均
    样本k阶中心矩
$$
X^-={1\over n}\sum^n_{i=1}X_i
$$
$$
S^2={1\over n-1}\sum^n_{i=1}(X_i-X^-)^2
$$
$$
A_k={1\over n}\sum^n_{i=1}X_i^k
$$
$$
M_k={1\over n}\sum^n_{i=1}(X_i-X^-)^k
$$
### 四种常用统计分布、三个结构定理、两个抽样分布定理
#### 标准正态分布
#### 卡方分布——平方和形式
相互独立的标准正态的平方和

结构定理：有n个服从标准正态分布的随机变量，则有
$$
\chi^2(i)=\sum^n_{i=1}X_i^2
$$
其自由度为正态分布的个数

数字特征

    期望就是自由度
    方差是二倍自由度
可加性

    两个卡方分布相加的结果服从自由度相加的卡方分布
大样本分位数

    将卡方分布标准化后约等于标准正态的上侧分位数
#### t分布
结构定理：有相互独立的X，Y。X是标准正态，Y是自由度为n的卡方分布，则有
$$
t(n)={X\over \sqrt{Y\over n}} 
$$
t分布关于y轴对称

依分布收敛到标准正态
$$
\lim _{x->+\infty}f_T(x)=\phi(x)
$$
#### F分布
结构定理：相互独立的两个卡方分布X，Y，有
$$
F(n_1,n_2)={{X\over n_1}\over{Y\over n_2}}
$$
且有1/F~F($n_2,n_1$)

要证上侧分位数相同，即从其构造入手，证大于其概率相等
#### 抽样分布定理
在一组正态总体样本中

样本均值的分布服从$N(\mu,\sigma^2/n)$
>均值$X^-$和方差$S^2$相互独立

>均值分布
${X^--\mu\over{\sigma\over\sqrt{n}}}$ ~ $N(0,1)$

>方差分布
${n-1\over\sigma ^2}S^2$ ~ $\chi^2(n-1)$

>结合前三条和T分布的结构定理：
${X^--\mu\over{S\over\sqrt{n}}}$ ~ $T(n-1)$

在两组正态总体样本中

方差作比${S_1^2/\sigma_1^2\over S_2^2/\sigma_2^2}$~$F(n_1-1,n_2-1)$

在$\sigma_1=\sigma_2$时，有${(X^--Y^-)-(\mu_1-\mu_2)\over S_w\sqrt{1/n_1+1/n_2}}$ ~ $T(n_1+n_2-2)$<br>其中$S_w=\sqrt{(n_1-1)S_1^2+(n_2-1)S_2^2\over n_1+n_2-2}$<br>分子是标准化，分母系数为两组正态需要除掉的，S是方差构造卡方分布除以自由度
## 参数估计
已知分布类型，利用样本对参数进行估计
### 参数的点估计
建立一个统计量，将统计值作为参数估计值

统计量：样本函数，不含其他参数

用统计值作为估计值
#### 矩估计(样本矩替换总体矩)
总体矩：$\gamma_k=E(X^k)$

样本矩：$A_k=1/n\sum ^n_ {r^2=1}X^k$

$$
E(A_k)=E(X^k)
$$
样本原点矩依概率收敛到总体原点矩

令$A_k=\gamma_k$

也就是直接用算术平均值估计期望<br>再反解出p
#### 极大似然估计M.L.E——按最大的可能性去估计
若在一次实验中A出现了，依据*小概率事件原理*，认为A发生的概率较大<br>因此我们期待找一些参数使得到该结果的概率**最大**

寻找出现该概率的函数表达式——**似然函数**L（联合分布律/联合概率密度）
$$
L(x_1\dots x_n;\theta)=\Pi^n_{i=1}P(X_i=x_i)=\Pi^n_{i=1}f(x_i;\theta)
$$
使似然函数得到极大值<br>为了方便求导，一般取对数之后再找驻点——寻找驻点的方程便称作**似然方程**

频率就是最大似然得到的**估计值**

统计量则是用随机变量替换对应值
#### 无法求导估计的极大似然估计——以均匀分布为例
均匀分布的概率密度函数是常数，估计使用的参数少，估计效果差

均匀分布范围尽可能小、且对所有x成立
#### 总结
矩估计参数简单，但有信息损失

极大似然估计精度较高

估计量不一定唯一（驻点）
### 估计量的优良性
一个参数的估计量不唯一，但需要选择优良的估计<br>如样本均值和样本方差均满足无偏、相合，且有最小方差

#### 无偏性
估计值的期望为真实值<br>估计值的散布以真实值为中心

满足无偏性的估计量即**无偏估计量**<br>**样本均值是期望的无偏估计量**<br>**样本方差(n-1)是方差的无偏估计量**

    证明时采用期望的线性性和可加性，以及和方差的变换

若只有在样本容量很大的时候才满足则称为渐近无偏估计量<br>**二阶中心矩是渐近无偏**，因此它不是样本方差

一个函数若存在无偏估计量称作是可估计函数

#### 有效性（首先保证无偏）
在中心附近越密集越好即估计量的方差小更有效<br>方差最小的称为最小方差无偏估计量（需要通过条件极值的拉格朗日乘数法求极值）

#### 相合性
容量越大估计越准即希望在n无穷增大时估计值依概率收敛于准确值<br>$\lim_{n->\infty}P\{\sum^n_{i=1}|\theta_n-\theta|<0\}=1$

### 区间估计
点估计缺陷：无从断定真实值及其可靠程度（偏离程度）

因此给出一个$\theta$的区间代替一个值，使

1. 在置信区间上的概率$P\{\theta_1 <= \theta <= \theta_2\}$尽可能大（可靠性）
2. 置信区间$\theta_2-\theta_1$尽可能小（精确性）
3. 给定一个小概率$\alpha$（显著性水平）使P的置信度为$1-\alpha$

置信度即置信区间能框住$\theta$的概率

在正态分布中，一般构造出$u_{\alpha/2}$这样的上侧分位数及形如$(-u_{\alpha/2},u_{\alpha/2})$的区间使置信度为$1-\alpha$
#### 枢轴变量法
##### 枢轴变量
$W(X_i,\theta)$中，必须有且仅有$\theta$是未知的，其余所有的X都应该是未知的——有利于解出W之后反解出$\theta$
1. 选取优良的估计量（样本均值、样本方差）
2. 构造枢轴变量$W(X_i,\theta)$
3. 确定W分布（一般具有经典分布）
4. 根据分布查上侧分位数$u_{(1-\alpha)/2}$和$u_{\alpha/2}$
   1. 取对称分位数原因在于区间长度小（除卡方分布）
   2. 得到$P\{u_{1-\alpha/2}<W(X_i,\theta)<u_{\alpha/2}\}$，其中$\alpha$事先给出
#### 单正态分布的置信区间
关键在于枢轴变量W如何取；遇到未知值用点估计代入另一参数

其中n为样本数，$X^-$为样本均值，$S^2$为样本方差
##### 估计$\mu$
- $\sigma$已知

构建标准正态分布 N(0,1)
$$
U={(X^--\mu)\over\sigma/\sqrt{n}}
$$
得到
$$
P\{u_{1-\alpha/2}<{\sqrt{n}(X^--\mu)\over\sigma}<u_{\alpha/2}\}>1-\alpha
$$
化简得到单独的$\mu$的区间
- $\sigma$未知：标准差顶替$\sigma$，但会构造出T分布

构建T分布 t(n-1)
$$
T={(X^--\mu)\over S/\sqrt{n}}
$$

##### 估计$\sigma$
- $\mu$已知

构造卡方分布 $\chi^2$(n)
$$
\chi^2={\sum^n_{i=1}(x_i-\mu)^2\over\sigma^2}
$$
得到
$$
P\{\chi^2_{1-\alpha/2}(n)<{\sum^n_{i=1}(x_i-\mu)^2\over\sigma^2}<\chi^2_{\alpha/2}(n)\}>1-\alpha
$$
- $\mu$未知：样本方差构造卡方（实质是样本均值顶替$\mu$）

构造卡方分布 $\chi^2$(n-1)
$$
\chi^2={(n-1)S^2\over\sigma^2}
$$
#### 双正态分布的置信区间
有X、Y两个相互独立的正态分布
##### 估计$\mu_1-\mu_2$（即构造了相加的正态分布）
- $\sigma$已知

根据可加性，构造标准正态分布
$$
U={{(X^--Y^-)-(\mu_1-\mu_2)}\over {\sqrt{\sigma_1^2/n1+\sigma_2^2/n_2}}}
$$
- $\sigma$未知，且$\sigma_1=\sigma_2$

根据可加性，构造T分布

需要注意单正态构造t(n-1)，双正态需要构造$t(n_1+n_2-2)$
$$
T={(X^--Y^-)-(\mu_1-\mu_2)\over S_w\sqrt{1/n_1+1/n_2}}
$$
其中
$$
S_w=\sqrt{(n_1-1)S_1^2+(n_2-1)S_2^2\over n_1+n_2-2}
$$
##### 估计$\sigma_2^2\over \sigma_1^2$
- 未知$\mu_1,\mu_2$

构造f分布：$F(n_1-1,n_2-1)$
$$
F={S_1^2/\sigma_1^2\over S_2^2/\sigma_2^2}
$$
注意f分布并不对称，建议先确定右侧分位数$\alpha$再确定左侧分位数$1-\alpha$
- 已知$\mu_1,\mu_2$

构造f分布：$F(n_1,n_2)$
$$
F={{\sum^{n_1}_{i=1}({X_i-\mu_1})^2/n\sigma^2_1}\over{\sum^{n_2}_{i=1}({X_i-\mu_2})^2/n\sigma^2_2}}
$$

## 假设检验
### 假设检验的基本思想
先提出一个假设

在被假设的小概率事件在一次实验中出现时，倾向于认为该事件并非小概率事件

小概率事件发生的概率
$$
P\{|X^--2|>k\}=\alpha
$$

假设检验有关于总体参数或总体分布<br>即未知数为参数或分布函数的参数

在假设检验时，需要考虑一对对立的假设<br>其中H0为原假设，H1为备选假设

    原假设等于，则备选假设不等
    原假设大于，则备选假设小于等于
    原假设小于，则备选假设大于等于
称满足原假设的区域为接受域，反之为 否定域
#### 基本步骤
提出原假设和与其对立的基本假设

寻找参数的优良估计量并建议统计量 作为检验，在原假设城里的情况下确定分布

选定显著性水平，确定否定域

判断是否接受原假设
#### 假设检验错误
假设检验的依据是小概率事件原则且是样本推断总体

因此无论接受或拒绝都可能做出错误的判断

第一类错误（弃真）

    H0成立但是被否定了

    条件概率：在H0成立的条件下发生了否定
可以计算得到弃真的概率即是显著性水平$\alpha$

第二类错误（纳伪）

    H0不成立但是被接受了

    条件概率：在H0不成立的条件下发生了肯定
由于在H0不成立的情况下不再服从标准正态，因此纳伪的概率不是$1-\alpha$ 

尽管第一类错误是可控的，但无法使两类错误都小<br>因此在给出原假设时将相对严重的作为第一类错误<br>保守原则：原假设趋向于没有变化
### 正态总体的参数检验
将枢轴变量中的未知参数用原假设代替得到检验统计量
#### U检验法（即检验期望已知方差）
即$\mu=\mu_0？$

拒绝域为$|u|>u_{\alpha/2}$

双样本中检验量为$\mu_1=\mu_2?$
#### T检验法（即检验期望未知方差）
即$\mu=\mu_0？$

拒绝域为$|u|>u_{\alpha/2}$
#### 卡方检验法（即检验方差）
即$\sigma^2=\sigma_0^2？$

接受域不对称，为$(u_{1-\alpha/2},u)$
#### F检验法
即$\sigma_1^2=\sigma_2^2？$

接受域不对称，为$(u_{1-\alpha/2},u)$
## 回归分析
### 相关关系和回归系数
关系有确定和不确定之分

希望构造函数近似非确定性关系

#### 条件期望
Y在X的影响下的集中点
$$
E(Y|X)=\int yf_{Y|X}(y|x)dy=\mu(x)
$$
在一定程度上表征了X和Y的关系，即相关关系
#### 回归函数
$$
\mu(x_1\dots x_n)=E(Y|X_1=x_1\dots X_n=x_n)
$$
这就是回归方程了，回归函数是确定性的，然而关系是不确定的
#### 随机误差修正
$$
\mu(x_1\dots x_n)+\epsilon
$$
希望误差的期望是0，且方差尽可能小
#### 单个变量X的回归函数
观察法：依据是小概率原理，认为数据分布在回归曲线附近
### 一元线性回归
$$
y=a+bx+\epsilon
$$
有$\epsilon$~$N(0,\sigma^2)$<br>a:回归常数<br>b:回归系数

成为一元线性正态回归模型
#### 估计参数优良性
$$
\hat{y_i}=\hat{a}+\hat{b}x_i
$$
选取ab的估计使残差平方和最小
$$
Q=\sum^n_{i=1}(y_i-\hat{y_i})^2=l_{yy}
$$
解得
$$
\hat{b}=l_{xy}/l_{xx}
$$
$$
\hat{a}=\bar{y}-\hat{b}\bar{x}
$$
以二阶原点矩作为矩估计量，但并不优良

一个无偏估计量是
$$
\bar{\sigma}^2=1/n-2\sum_{i-1}^n(y_i-\hat{y})^2
$$
### 系数的假设检验
#### 相关系数法
$$
\rho_{XY}={{E((X-E(X))(Y-E(Y)))}\over{\sqrt{D(X)D(Y)}}}={l_{xy}\over\sqrt{l_{xx}l_{yy}}}=R
$$
R=1时XY存在线性相关
# 复习大纲
## 古典概率
### 鸽笼问题(m<=n<=N)
>一个鸽厂有n只鸽子，它们等可能地飞入N个鸽笼中的一个
1. A={指定的n个鸽笼各有一只鸽子}
2. B={恰好在n个鸽笼中各有一只鸽子}
3. C={某指定的鸽笼中有m只鸽子}
---
通过样本点数量求频率

1. 分母为总情况，有$N^n$种情况；分子：第一只进去的鸽子有n种，到最后一只进去的只有1种，因此有$n!$种情况。
2. 分母为总情况，有$N^n$种情况；分子：先指定这n个鸽笼$C_N^n$，再乘上$n!$。
3. 分母为总情况，有$N^n$种情况；分子：选择m只鸽子进入该鸽笼$C_n^m$，剩下的n-m只鸽子还有N-1个鸽笼$(N-1)^{n-m}$
---
1. $P(A)={{n!}\over{N^n}}$
2. $P(B)={{C_N^nn!}\over{N^n}}$
3. $P(C)={{C_n^m(N-1)^{n-m}}\over{N^n}}$
### 抽球问题
10球，4红，6白，抽3，求2红1白概率
1. 放回
2. 不放回
---
1. 乘法公式计算分子和分母样本点；或分解为多个基本事件并将其相乘
2. 运用组合数计算分子和分母样本点